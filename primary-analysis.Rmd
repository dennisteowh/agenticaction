---
title: "Primary Analysis for Learning from Agentic Actions"
author: "Dennis W.H. Teo"
output:
  html_document:
    df_print: paged
    number_sections: yes
    theme: readable
    highlight: tango
    toc: yes
    toc_depth: 3
fontsize: 16pt
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE)
```

```{r echo = F}


library(tidyverse)
library(ggplot2)
library(car)
library(rstatix)
library(langcog)
library(Rlab)

library(readr)
scl_dat <- read_csv("scl_dat.csv")

```

```{r}
normalise <- function(x){
  x_sum <- sum(x,na.rm=T)
  output <- x/x_sum
  return(output)
}

sample_bern <- function(N, dist){
  output <- c()
  for(i in 1:length(dist)){
   output <- c(output, rbern(N, dist[i])*i) 
  }
  return(output)
}

 # function to compute rmse
rmse <- function(x, target){
    pred <- x
    loss <- sum(sqrt((target - pred)^2))/length(target)

  return(loss)
}

# function to grid search for lowest RMSE
rmse2 <- function(x,y, target, w){
  output <- c()
  for(i in w){
    pred <- i*x+(1-i)*y
    loss <- sum(sqrt((target - pred)^2))/length(target)
    output <- c(output, loss)
  }
  optimal_value = min(output)
  optimal <- which(output == min(output))
  output <- data.frame(w=w, loss=output)
  print(paste("lowest RMSE is",  optimal_value, "at",  w[optimal]))

  return(output)
}

gather.keep <- function(df, gather.col, keep = NULL, key = "key", value= "value") {
  
  require(tidyverse)
  
  if (is.null(keep)) {
    
    result <- gather(df[, gather.col], key = key, value = value)
    return(result)
    
  } else {
    
    result <- gather(df[, gather.col], key = key, value = value) 
    
    no.var <- length(gather.col) 
    
    grow <- df[, c(gather.col, keep)]
    temp <- grow
    for (i in 1:(no.var - 1)){
    temp <- rbind(temp, grow) ##multiplying temp to match rows for result
    
    }
    
    result <- cbind(result, temp[, keep])
    
    colnames(result) <- c(key, value, keep)
    
    return(result)
  }
  
  
}

```


# Descriptives and outliers
```{r}

# fail attention check
scl_dat <- scl_dat[scl_dat$attention!="4",]

# outlier for rt
rt_range <- 3*sd(scl_dat$total_rt)
slow <- which(scl_dat$total_rt > mean(scl_dat$total_rt,na.rm = T) + rt_range)
fast <- which(scl_dat$total_rt < mean(scl_dat$total_rt,na.rm = T) - rt_range)
length(slow) + length(fast)

# remove slow
scl_dat <- scl_dat[-slow,]

# nfail
n_fails <- which(scl_dat$n_fails > 3)
length(n_fails)

nrow(scl_dat)


```

```{r}
# gender
table(scl_dat$gender)

table(scl_dat$gender)[[1]]/length(scl_dat$gender) # prop females

# age
mean(scl_dat$age,na.rm = T) #age
sd(scl_dat$age,na.rm = T)

# native language
table(scl_dat$language)
(length(scl_dat$language) - 2)/length(scl_dat$language)


```


```{r}
# change to long form
scl_dat_long <- gather.keep(scl_dat, gather.col = c("cause_blue","cause_pink","cause_both","cause_bp"), keep = c("workerid", "condition"), key = "structure",value="likelihood")

# normalised ratings
scl_dat_long_norm <- gather.keep(scl_dat, gather.col = c("cause_blue_norm","cause_pink_norm","cause_both_norm","cause_bp_norm"), keep = c("workerid", "condition"), key = "structure",value="likelihood")

```


# Primary Analysis

```{r}

intention <- scl_dat %>%
  filter(condition == "condition 1")

unintention <- scl_dat %>%
  filter(condition == "condition 2")

two_agent <- scl_dat %>%
  filter(condition == "condition 3")

# intentional vs unintentional on B -> P
t.test(intention$cause_bp, unintention$cause_bp)

# intentional vs two-agent on B -> P
t.test(intention$cause_bp, two_agent$cause_bp)

# intentional vs two-agent on B 
t.test(two_agent$cause_blue, intention$cause_blue)

# unintentional vs two-agent on B 
t.test(two_agent$cause_blue, unintention$cause_blue)

# anova on both boxes
Anova(lm(cause_both ~ condition, data = scl_dat))


```


# Manipulation Check

## intentional human vs unintentional bot
```{r}
intention <- scl_dat %>%
  filter(condition == "condition 1")

unintention <- scl_dat %>%
  filter(condition == "condition 2")


t.test(intention$intention, unintention$intention)
```

```{r}

scl_dat %>%
  group_by(condition) %>%
  summarise(mean = mean(intention, na.rm = T),
            sd = sd(intention, na.rm=T))
```


## within two-agent: human vs bot

```{r}

two_agent <- scl_dat %>%
  filter(condition == "condition 3")

t.test(two_agent$intention, two_agent$intention_bot, paired = T)

# unintentional bot vs two-agent bot 
t.test(unintention$intention, two_agent$intention_bot)

```


# Searching for mixture parameters

```{r}
human0.0 <- normalise(c(.13366,.13433,.101+.09233,.39566))

human0.05 <- normalise(c(.11900,.13666,.09566+.09266,.40466))

human0.1 <- normalise(c(.109,.141,.10533+.09533,.40466))

human0.15 <- normalise(c(.07399,.14066,.116+.11199,.41133))

human0.2 <- normalise(c(0,.16666,.12133+.11566,.47866))

intention_data <- scl_dat_long_norm %>%
  filter(condition == "condition 1") %>%
  spread(key = structure, value = likelihood)

target <- c(mean(intention_data$cause_blue_norm, na.rm=T), 
         mean(intention_data$cause_pink_norm, na.rm=T), 
         mean(intention_data$cause_both_norm, na.rm=T), 
         mean(intention_data$cause_bp_norm, na.rm=T)
            )
```

```{r}
rmse(human0.0, target)

rmse(human0.05, target)

rmse(human0.1, target) # lowest RMSE

rmse(human0.15, target)

rmse(human0.2, target)
```

```{r}
human <- normalise(c(.109,.141,.10533+.09533,.40466))

robot <- normalise(c(.353,.47333,.01233+.01033,.02633))

human_two_agent <- normalise(c(.96066,0,0,0))

two_agent_independent <- .5*human_two_agent + .5*robot

```




## semi-intentional
```{r}

unintention_data <- scl_dat_long_norm %>%
  filter(condition == "condition 2") %>%
  spread(key = structure, value = likelihood)

target <- c(mean(unintention_data$cause_blue_norm, na.rm=T), 
         mean(unintention_data$cause_pink_norm, na.rm=T), 
         mean(unintention_data$cause_both_norm, na.rm=T), 
         mean(unintention_data$cause_bp_norm, na.rm=T)
            )

set.seed(100)

weights <- 0:10/10

# search for mixture parameter for semi intentional
rmse2(human, robot, target, weights)

# compute weight sum of posteriors
.9*human + .1*robot

semi <- .9*human + .1*robot

```

## two_agent coop

```{r}

two_agent_data <- scl_dat_long_norm %>%
  filter(condition == "condition 3") %>%
  spread(key = structure, value = likelihood)

target <- c(mean(two_agent_data$cause_blue_norm, na.rm=T), 
         mean(two_agent_data$cause_pink_norm, na.rm=T), 
         mean(two_agent_data$cause_both_norm, na.rm=T), 
         mean(two_agent_data$cause_bp_norm, na.rm=T)
            )

coop <- human

# search for mixture parameters for two-agent coop

set.seed(100)

weights <- 0:10/10

rmse2(two_agent_independent, coop, target, weights)

.3*two_agent_independent + .7*coop

two_agent_coop <- .3*two_agent_independent + .7*coop

```



# Graphs

```{r}
scl_dat_long_grp <- scl_dat_long_norm %>% group_by(condition, structure)

# get standard errors and CIs
summary1 <- multi_boot_standard(scl_dat_long_grp, col="likelihood")

empty1 <- data.frame(condition = rep("condition 4", 4), 
                    structure = c("cause_blue_norm", "cause_pink_norm", "cause_both_norm", "cause_bp_norm"),
                    ci_lower = rep(NA, 4),
                     ci_upper = rep(NA, 4),
                     mean = rep(NA, 4)
                    )

empty2 <- data.frame(condition = rep("condition 5", 4), 
                    structure = c("cause_blue_norm", "cause_pink_norm", "cause_both_norm", "cause_bp_norm"),
                    ci_lower = rep(NA, 4),
                     ci_upper = rep(NA, 4),
                     mean = rep(NA, 4)
                    )

 summary1$Condition <- ifelse(summary1$condition == "condition 1", 5, 
                              ifelse(summary1$condition == "condition 2", 3, 1
                                     ))

summary1mod <- summary1 %>%
  full_join(empty1) %>%
  full_join(empty2)

 summary1mod$Condition <- ifelse(summary1mod$condition == "condition 1", 5, 
                              ifelse(summary1mod$condition == "condition 2", 3, 
                                     ifelse(summary1mod$condition == "condition 3", 1, 
                                            ifelse(summary1mod$condition == "condition 4", 2, 4)
                                     )))

```


```{r}


summary1$Structure <- factor(summary1$structure, labels = c("B","P","B & P", "B -> P", "P -> B"), levels = c("cause_blue_norm", "cause_pink_norm", "cause_both_norm", "cause_bp_norm", "cause_pb_norm"))

summary1mod$Structure <- factor(summary1mod$structure, labels = c("B","P","B & P", "B -> P", "P -> B"), levels = c("cause_blue_norm", "cause_pink_norm", "cause_both_norm", "cause_bp_norm", "cause_pb_norm"))

# summary1$Condition <- factor(summary1$condition,levels = c("condition 1","condition 2","condition 3") , labels = c("Intentional", "Unintentional", "Two agent"))


breaks <- unique(summary1$Condition)

plot2 <- ggplot(summary1mod, aes(x = Condition, y = mean, fill = Structure)) + 
  geom_bar(stat = "identity", position = "dodge") +
  geom_errorbar( data = summary1, aes(x = Condition,ymin=ci_lower, ymax=ci_upper, fill= Structure), width=.2,
                 position=position_dodge(.9), width = .5, size = .5)+
  ylab("likelihood ratings") + 
  ylim(0,.75) +
  scale_x_reverse(breaks=breaks, labels=rev(c("Two-agent", "Robot","Human") )) +
  scale_fill_manual(values = c("#0072b2","#CC79A7",  "#009E73",  "#D55E00")) +
  theme_bw() + xlab("")+
  geom_vline(xintercept=2.5, linetype="dashed")+
  geom_vline(xintercept=4.5, linetype="dashed")+
  theme(text = element_text(size = 32),
        axis.text.x = element_text(face = "bold", size = 36, hjust = 0.5),
        plot.title = element_text(face = "bold", size = 32, hjust = 0.5)) +
  ggtitle("Human Data")

```

```{r}

# intentional agent posterior
human.data <- data.frame(
  Structure = c("B", "P", "B & P", "B -> P"),
  mean  = human,
  Condition = rep("Intentional", 4)
)

# unintentional agent posterior
robot.data <- data.frame(
  Structure = c("B", "P", "B & P", "B -> P"),
  mean  = robot,
  Condition = rep("Unintentional", 4)
)

# semi intentional-agent posterior
robot2.data <- data.frame(
  Structure = c("B", "P", "B & P", "B -> P"),
  mean = semi,
  Condition = rep("Semi-intentional", 4)
)

# two agent independent posterior 
two_agent.data <- data.frame(
  Structure = c("B", "P", "B & P", "B -> P"),
  mean = two_agent_independent,
  Condition = rep("Two-agent-solo", 4)
  )

# two agent coop posterior 
two_agent2.data <- data.frame(
  Structure = c("B", "P", "B & P", "B -> P"),
  mean = two_agent_coop,
  Condition = rep("Two-agent-coop", 4)
  )


pred.data <- as.data.frame(rbind(human.data, robot.data, robot2.data, two_agent.data, two_agent2.data))

pred.data$Condition <- factor(pred.data$Condition, levels = c("Intentional", "Unintentional","Semi-intentional", "Two-agent-solo","Two-agent-coop"),
                              labels = c("Intentional", "Unintentional","Semi-intentional", "Two-agent-independent","Two-agent-coop"), ordered = T)

pred.data$Structure <- factor(pred.data$Structure, levels = c("B", "P", "B & P", "B -> P"))

plot1 <- ggplot(pred.data, aes(x = Condition, y = mean, fill=Structure)) + 
  geom_bar(stat = "identity", position = "dodge") +
  ylab("likelihood ratings") + xlab("") + 
  scale_fill_manual(values = c("#0072b2","#CC79A7",  "#009E73", "#D55E00")) +
  theme_bw() +
  ylim(0,.75) +
  geom_vline(xintercept=1.5, linetype="dashed")+
  geom_vline(xintercept=3.5, linetype="dashed")+
  theme(text = element_text(size = 28),
        axis.text.x = element_text(face = "bold", size = 28, hjust = 0.5),
        plot.title = element_text(face = "bold", size = 28, hjust = 0.5)) +
  ggtitle("Model Predictions")+
  annotate(geom="text", x=1.08, y=.6, label=expression('D'["KS"] * '= .03') , size = 8  )+
  annotate(geom="text", x=2.08, y=.6, label=expression('D'["KS"] * '= .63'^"*") , size = 8  )+
  annotate(geom="text", x=3.08, y=.6, label=expression('D'["KS"] * '= .10')  , size = 8 )+
  annotate(geom="text", x=4.08, y=.6, label=expression('D'["KS"] * '= .58'^"*"), size = 8   )+
  annotate(geom="text", x=5.08, y=.6, label=expression('D'["KS"] * '= .10') , size = 8 )

library(stringr)
str_wrap_factor <- function(x, ...) {
  levels(x) <- str_wrap(levels(x), ...)
  x
}

plot3 <- plot1 + aes(str_wrap_factor(Condition, 10), mean) + xlab(NULL) +
  ylab("likelihood ratings")


```


```{r fig.height=20, fig.width=24}
# note: the KSD estimates are corrected and different from the paper (our previous estimates tended to underestimate the KSD). 
# However, the corrected estimates lead to qualitatively similar conclusions 

library(grid)
grid.newpage()
grid.draw(rbind(ggplotGrob(plot2), ggplotGrob(plot3), size = "last"))

```



# Fit statistics

## intention_data - ksd

```{r}

intention_data <- scl_dat_long_norm %>%
  filter(condition == "condition 1") %>%
  spread(key = structure, value = likelihood)

causes <- c("cause_blue_norm", "cause_pink_norm" , "cause_both_norm", "cause_bp_norm")

set.seed(100)

intention_dist <- matrix(nrow=nrow(intention_data), ncol = length(causes))
# convert human data into categories by sampling
for (i in 1:length(causes)){
  intention_dist[,i] <- rbern(nrow(intention_data), rep(as.vector(unlist( intention_data[, causes[i]]))))*i
}
intention_dist <- intention_dist[intention_dist!=0]
table(intention_dist)

# sample from predicted posterior
intention_pred <- sample_bern(10000, human) # compare to population
intention_pred <- intention_pred[intention_pred!=0]
table(intention_pred)

# note: these are corrected estimates from the paper (our previous estimates tended to underestimate the KSD). 
# However, the corrected estimates lead to qualitatively similar conclusions 
ks.test(intention_pred, intention_dist)

```



## unintention_data - ksd

```{r}

unintention_data <- scl_dat_long_norm %>%
  filter(condition == "condition 2") %>%
  spread(key = structure, value = likelihood)

causes <- c("cause_blue_norm", "cause_pink_norm" , "cause_both_norm", "cause_bp_norm")

set.seed(100)

unintention_dist <- matrix(nrow=nrow(unintention_data), ncol = length(causes))
# convert human data into categories by sampling
for (i in 1:length(causes)){
  unintention_dist[,i] <- rbern(nrow(unintention_data), as.vector(unlist( unintention_data[, causes[i]])))*i
}
unintention_dist <- unintention_dist[unintention_dist!=0]
table(unintention_dist)

# sample from predicted posterior
unintention_pred <- sample_bern(10000, robot)
unintention_pred <- unintention_pred[unintention_pred!=0]
table(unintention_pred)

# note: these are corrected estimates from the paper (our previous estimates tended to underestimate the KSD). 
# However, the corrected estimates lead to qualitatively similar conclusions 
ks.test(unintention_pred, unintention_dist)


```


## semi-intention_data - ksd

```{r}

unintention_data <- scl_dat_long_norm %>%
  filter(condition == "condition 2") %>%
  spread(key = structure, value = likelihood)

causes <- c("cause_blue_norm", "cause_pink_norm" , "cause_both_norm", "cause_bp_norm")

set.seed(100)

unintention_dist <- matrix(nrow=nrow(unintention_data), ncol = length(causes))
# convert human data into categories by sampling
for (i in 1:length(causes)){
  unintention_dist[,i] <- rbern(nrow(unintention_data), as.vector(unlist( unintention_data[, causes[i]])))*i
}
unintention_dist <- unintention_dist[unintention_dist!=0]
table(unintention_dist)

# sample from predicted posterior
semiintention_pred <- sample_bern(10000, semi)
semiintention_pred <- semiintention_pred[semiintention_pred!=0]
table(unintention_pred)

# note: these are corrected estimates from the paper (our previous estimates tended to underestimate the KSD). 
# However, the corrected estimates lead to qualitatively similar conclusions 
ks.test(semiintention_pred, unintention_dist)


```


## two_agent_data:independent - ksd

```{r}

two_agent_data <- scl_dat_long_norm %>%
  filter(condition == "condition 3") %>%
  spread(key = structure, value = likelihood)

causes <- c("cause_blue_norm", "cause_pink_norm" , "cause_both_norm", "cause_bp_norm")

set.seed(100)

two_agent_dist <- matrix(nrow=nrow(two_agent_data), ncol = length(causes))
# convert human data into categories by sampling
for (i in 1:length(causes)){
  two_agent_dist[,i] <- rbern(nrow(two_agent_data), as.vector(unlist( two_agent_data[, causes[i]])))*i
}
two_agent_dist <- two_agent_dist[two_agent_dist!=0]
table(two_agent_dist)

# sample from predicted posterior
independent_pred <- sample_bern(10000, two_agent_independent)
independent_pred <- independent_pred[independent_pred!=0]
table(independent_pred)

# note: these are corrected estimates from the paper (our previous estimates tended to underestimate the KSD). 
# However, the corrected estimates lead to qualitatively similar conclusions 
ks.test(independent_pred, two_agent_dist)

```

## two_agent_data:coop - ksd

```{r}

two_agent_data <- scl_dat_long_norm %>%
  filter(condition == "condition 3") %>%
  spread(key = structure, value = likelihood)

causes <- c("cause_blue_norm", "cause_pink_norm" , "cause_both_norm", "cause_bp_norm")


set.seed(100)

two_agent_dist <- matrix(nrow=nrow(two_agent_data), ncol = length(causes))
# convert human data into categories by sampling
for (i in 1:length(causes)){
  two_agent_dist[,i] <- rbern(nrow(two_agent_data), as.vector(unlist( two_agent_data[, causes[i]])))*i
}
two_agent_dist <- two_agent_dist[two_agent_dist!=0]
table(two_agent_dist)

# sample from predicted posterior
coop_pred <- sample_bern(10000, two_agent_coop)
coop_pred <- coop_pred[coop_pred!=0]
table(coop_pred)

# note: these are corrected estimates from the paper (our previous estimates tended to underestimate the KSD). 
# However, the corrected estimates lead to qualitatively similar conclusions 
ks.test(coop_pred, two_agent_dist)


```







